{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d4c800-fa83-4d83-a055-fe5eca6371cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     11990\n",
      "           1       0.64      0.40      0.49      1574\n",
      "\n",
      "    accuracy                           0.90     13564\n",
      "   macro avg       0.78      0.69      0.72     13564\n",
      "weighted avg       0.89      0.90      0.89     13564\n",
      "\n",
      "All artifacts saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib  # Changed from pickle to joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#%% Data Loading\n",
    "data = pd.read_csv(r\"C:\\Users\\Yash\\OneDrive\\Desktop\\Deployment_Streamkit\\bank-full.csv\", sep=';')\n",
    "data = data.rename(columns={'y': 'Subscribed'})  # Corrected spelling\n",
    "\n",
    "#%% Data Preparation\n",
    "data[data.select_dtypes(include=['object']).columns] = data.select_dtypes(include=['object']).astype('category')\n",
    "\n",
    "#%% Train-Test Split\n",
    "X = data.drop(['Subscribed'], axis=1)\n",
    "y = data['Subscribed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)\n",
    "\n",
    "#%% Preprocessing Setup\n",
    "# Initialize encoders and scalers\n",
    "education_encoder = LabelEncoder()\n",
    "target_encoder = LabelEncoder()\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#%% Feature Engineering\n",
    "# Process education column\n",
    "X_train['education'] = education_encoder.fit_transform(X_train['education'])\n",
    "X_test['education'] = education_encoder.transform(X_test['education'])\n",
    "\n",
    "# Process target variable\n",
    "y_train = target_encoder.fit_transform(y_train)\n",
    "y_test = target_encoder.transform(y_test)\n",
    "\n",
    "# Process categorical features\n",
    "categorical_columns = X.select_dtypes(include=['category', 'object']).columns.drop('education')\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_cat = pd.DataFrame(ohe.fit_transform(X_train[categorical_columns]),\n",
    "                          columns=ohe.get_feature_names_out(categorical_columns),\n",
    "                          index=X_train.index)\n",
    "\n",
    "# Transform test data\n",
    "X_test_cat = pd.DataFrame(ohe.transform(X_test[categorical_columns]),\n",
    "                         columns=ohe.get_feature_names_out(categorical_columns),\n",
    "                         index=X_test.index)\n",
    "\n",
    "# Combine features\n",
    "X_train = pd.concat([X_train.drop(columns=categorical_columns), X_train_cat], axis=1)\n",
    "X_test = pd.concat([X_test.drop(columns=categorical_columns), X_test_cat], axis=1)\n",
    "\n",
    "#%% Feature Scaling\n",
    "numerical_columns = X_train.select_dtypes(include=['number']).columns\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "#%% Model Training\n",
    "model = RandomForestClassifier(random_state=25)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#%% Model Evaluation\n",
    "print(\"Model Evaluation:\")\n",
    "print(classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "#%% Save Artifacts\n",
    "joblib.dump(model, 'model.joblib')\n",
    "joblib.dump(education_encoder, 'education_encoder.joblib')\n",
    "joblib.dump(target_encoder, 'target_encoder.joblib')\n",
    "joblib.dump(ohe, 'onehot_encoder.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "print(\"All artifacts saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
